# -*- coding: utf-8 -*-
"""G_compute.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G2FTyzPhJR57VmXEMaRC52U9jexU04M2
"""

# Import necessary libraries
!pip install networkx
import pandas as pd
from dateutil import parser
from dateutil.parser import isoparse
from datetime import datetime, time, timedelta
from networkx.algorithms.dag import descendants

def filter_and_calculate(csv_file_path):
    # Read 2018 Maven data and convert to a dataframe
    valid_rows = []
    with open(csv_file_path, "r") as file:
        for line in file:
            try:
                row = line.strip().split(",")
                valid_rows.append(row)
            except Exception as e:
                print(f"Skipping row due to error: {e}")

    df = pd.DataFrame(valid_rows)

    # Remove numeric headers
    df.columns = df.iloc[0]
    df = df[1:]
    df = df.rename_axis(None, axis=1)

    # Extract relevant columns
    new_df = df[['Artifact', 'Dependencies', 'Upstream Release Date', 'Dependency Release Date']].copy()

    # Split source and target columns
    new_df[['Source_Group_Id', 'Source_Artifact_Id', 'Source_Version']] = df['Artifact'].str.split(':', expand=True)
    new_df[['Target_Group_Id', 'Target_Artifact_Id', 'Target_Version']] = df['Dependencies'].str.split(':', expand=True)

    df.drop(columns=['Artifact', 'Dependencies'], inplace=True)

    # Rename columns
    df = df.rename(columns={'Upstream Release Date': 'Source Release Date', 'Dependency Release Date': 'Target Release Date'})

    # Add new columns
    df['Source Release Year'] = df['Source Release Date'].str[:4]
    df['Target Release Year'] = df['Target Release Date'].str[:4]

    df = pd.concat([df, new_df], axis=1)

    desired_columns_order = ['Source_Group_Id', 'Source_Artifact_Id', 'Source_Version','Source Release Date', 'Source Release Year','Target_Group_Id', 'Target_Artifact_Id', 'Target_Version',
                              'Target Release Date',  'Target Release Year']

    df = df[desired_columns_order]

    df = df.drop(columns=['Source_Artifact_Id', 'Target_Artifact_Id'])

    filtered_dfs = []
    for year, group in df.groupby('Target Release Year'):
        filtered_group = group.drop_duplicates(subset=['Target_Group_Id'])
        filtered_dfs.append(filtered_group)

    filtered_df = pd.concat(filtered_dfs)

    filtered_df.to_csv('G.tsv', sep='\t', index=False)
    return filtered_df